{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42621bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\parvb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\parvb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc32897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5f33180",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d678890",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = pd.read_excel(r'face-mask.xlsx', 'Sheet1')\n",
    "document['body']=document['body'].apply(str)\n",
    "document['body']=document['body'].str.lower()\n",
    "rows = document.iloc[-1:].index\n",
    "df2 = pd.DataFrame(columns = ['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45a230e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,rows.start+1):\n",
    "    word_list = nltk.word_tokenize(document['body'][i])\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    #word_list = nltk.word_tokenize(lemmatized_output)\n",
    "    #stemmed_output = ' '.join([ps.stem(w) for w in word_list])\n",
    "    df2 = df2.append({'lemmatized': lemmatized_output}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9413ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df2['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f16b5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=10000, n_clusters=5, n_init=100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=10000, n_init=100)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd865959",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2f21c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "mask\n",
      "like\n",
      "good\n",
      "wa\n",
      "layer\n",
      "money\n",
      "buy\n",
      "paper\n",
      "comfortable\n",
      "feel\n",
      "Cluster 1:\n",
      "quality\n",
      "poor\n",
      "bad\n",
      "mask\n",
      "good\n",
      "horrible\n",
      "terrible\n",
      "buy\n",
      "low\n",
      "layer\n",
      "Cluster 2:\n",
      "smell\n",
      "chemical\n",
      "like\n",
      "mask\n",
      "strong\n",
      "bad\n",
      "horrible\n",
      "terrible\n",
      "weird\n",
      "bag\n",
      "Cluster 3:\n",
      "great\n",
      "value\n",
      "price\n",
      "product\n",
      "fit\n",
      "mask\n",
      "comfortable\n",
      "deal\n",
      "quality\n",
      "work\n",
      "Cluster 4:\n",
      "cheap\n",
      "material\n",
      "quality\n",
      "feel\n",
      "mask\n",
      "buy\n",
      "product\n",
      "worth\n",
      "like\n",
      "super\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    " print(\"Cluster %d:\" % i),\n",
    " for ind in order_centroids[i, :10]:\n",
    "     print('%s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e99e27af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>totally recommend ! ! ! these mask do not smel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this item scared u . it is one ply , not three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is just ridiculously unsafe , i had to po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do not buy ! ! ! ! this is how my mask came st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just one look at my child 's face and you can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized\n",
       "0  totally recommend ! ! ! these mask do not smel...\n",
       "1  this item scared u . it is one ply , not three...\n",
       "2  this is just ridiculously unsafe , i had to po...\n",
       "3  do not buy ! ! ! ! this is how my mask came st...\n",
       "4  just one look at my child 's face and you can ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af3d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
