{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b86c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\namra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4868499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3196f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\namra\\Downloads\\data-book.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd33115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['rating']==1]\n",
    "df2 = df[df['rating']==2]\n",
    "df3 = df[df['rating']==3]\n",
    "df4 = df[df['rating']==4]\n",
    "df5 = df[df['rating']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd420b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 =''\n",
    "for i in df1['body']:\n",
    "    text1+=i\n",
    "text2 =''\n",
    "for i in df2['body']:\n",
    "    text2+=i\n",
    "text3 =''\n",
    "for i in df3['body']:\n",
    "    text3+=i\n",
    "text4 =''\n",
    "for i in df4['body']:\n",
    "    text4+=i\n",
    "text5 =''\n",
    "for i in df5['body']:\n",
    "    text5+=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef601fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "f = open(r'C:\\Users\\namra\\glove.6B\\glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f254f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e58052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text1):\n",
    "    doc = nlp(text1)\n",
    "    tokens=[token.text for token in doc]\n",
    "    #print(tokens)\n",
    "    from string import punctuation\n",
    "    punctuation=punctuation+'n'\n",
    "    word_freq={}\n",
    "    stop_words= list(STOP_WORDS)\n",
    "\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stop_words:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_freq.keys():\n",
    "                    word_freq[word.text]= 1\n",
    "                else:\n",
    "                    word_freq[word.text]+= 1 \n",
    "        #print(word_freq)\n",
    "\n",
    "    x=(word_freq.values())\n",
    "    a=list(x)\n",
    "    a.sort()\n",
    "    max_freq=a[-1]\n",
    "\n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word]=word_freq[word]/max_freq \n",
    "    #print(word_freq)\n",
    "\n",
    "    sent_score={}\n",
    "    sent_tokens=[sent for sent in doc.sents]\n",
    "    #print(sent_tokens)\n",
    "\n",
    "    for sent in sent_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_freq.keys():\n",
    "                if sent not in sent_score.keys():\n",
    "                    sent_score[sent]=word_freq[word.text.lower()]\n",
    "                else:\n",
    "                    sent_score[sent]+= word_freq[word.text.lower()] \n",
    "    #print(sent_score)\n",
    "\n",
    "    \n",
    "    sentences = nlargest(n=1000,iterable=sent_score,key=sent_score.get) \n",
    "    #print(summary)\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = str(sentences[i])\n",
    "\n",
    "\n",
    "    clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \", regex=True)\n",
    "    clean_sentences = [s.lower() for s in clean_sentences]\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "\n",
    "    sentence_vectors = []\n",
    "    for i in clean_sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vectors.append(v)\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    new_text1 = ''\n",
    "    for i in range(20):\n",
    "        new_text1 += ranked_sentences[i][1]\n",
    "    return new_text1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cad29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small (https://huggingface.co/t5-small)\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "summarizer = transformers.pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1e26096",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text1 = extract(text1)\n",
    "new_text2 = extract(text2)\n",
    "new_text3 = extract(text3)\n",
    "new_text4 = extract(text4)\n",
    "new_text5 = extract(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c7f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#summarizer2 = transformers.pipeline(\"summarization\")\n",
    "summarized1 = summarizer(new_text1, min_length=75, max_length=300)\n",
    "summarized2 = summarizer(new_text2, min_length=75, max_length=300)\n",
    "summarized3 = summarizer(new_text3, min_length=75, max_length=300)\n",
    "summarized4 = summarizer(new_text4, min_length=75, max_length=300)\n",
    "summarized5 = summarizer(new_text5, min_length=75, max_length=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e4f7273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Alberto Cairo's book is about visualization but only has three EXAMPLES . the book has a chart, which is re-used like 5 times in the book . it seems to be intended for people who have only used basic chart tools in excel and wish to produce only slightly less awful charts . but started reading and half the book is not there .\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80287c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the book has a pivotal flaw: it assumes your data is already there, processed, understood, and ready to be presented; something that is by far the hardest to achieve .the book is not a stats book and should not be considered anything more than a graphics guide to power point and excel.the reader must belief that author opinion is good, and you are good to go.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a33b1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"the first portion of the book is incorrectly cut and bound together at an angle . it's mostly a bunch of (very good) design types on presenting data . the problem with this book - it does not “show” you how to create the visuals . if you have it then it will probably come in handy here and there .\"}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bba1d651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the author has done a great job explaining concepts on all the different attributes that make a good story when using data . this book is great for anyone who needs to improve the way they use and design charts, as well as those that need to present data to others . the book opens your eyes to some of the dumb ways we try to report out information to business leaders and also push us to think about the multiple ways we can present data.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cbb7441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"this book looks behind the scenes at how our brains work and how we process data . it gives us an incredible depth and breadth of insight into the mind and how it sees things . this book is one of the best data oriented books I've read in a long time . the author presents good ideas and examples, it helped me improve my visualization skills .\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f652ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarized1 [{'summary_text': \"Alberto Cairo's book is about visualization but only has three EXAMPLES . the book has a chart, which is re-used like 5 times in the book . it seems to be intended for people who have only used basic chart tools in excel and wish to produce only slightly less awful charts . but started reading and half the book is not there .\"}]\n",
      "summarized2 [{'summary_text': 'the book has a pivotal flaw: it assumes your data is already there, processed, understood, and ready to be presented; something that is by far the hardest to achieve .the book is not a stats book and should not be considered anything more than a graphics guide to power point and excel.the reader must belief that author opinion is good, and you are good to go.'}]\n",
      "summarized3 [{'summary_text': \"the first portion of the book is incorrectly cut and bound together at an angle . it's mostly a bunch of (very good) design types on presenting data . the problem with this book - it does not “show” you how to create the visuals . if you have it then it will probably come in handy here and there .\"}]\n",
      "summarized4 [{'summary_text': \"the author has done a great job explaining concepts on all the different attributes that make a good story when using data . this book opens your eyes to some of the dumb ways we try to report out information to business leaders . it's filled with valuable examples of good vs. bad ways to create data visualizations . if you want to take advantage of this book big time then buy a printed version .\"}]\n",
      "summarized5 [{'summary_text': 'this book looks behind the scenes at how our brains work and how we process data . it gives us an incredible depth and breadth of insight into the mind and how it sees things . this book is a fantastic book on your journey of learning effective data visualization . if you are already familiar with data analytics tools like Tableau, you need this book .'}]\n"
     ]
    }
   ],
   "source": [
    "print('summarized1',summarized1)\n",
    "print('summarized2',summarized2)\n",
    "print('summarized3',summarized3)\n",
    "print('summarized4',summarized4)\n",
    "print('summarized5',summarized5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d338a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
